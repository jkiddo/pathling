"use strict";(self.webpackChunkpathling_site=self.webpackChunkpathling_site||[]).push([[0],{3905:(e,a,t)=>{t.d(a,{Zo:()=>p,kt:()=>h});var n=t(7294);function r(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function l(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function s(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?l(Object(t),!0).forEach((function(a){r(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):l(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function i(e,a){if(null==e)return{};var t,n,r=function(e,a){if(null==e)return{};var t,n,r={},l=Object.keys(e);for(n=0;n<l.length;n++)t=l[n],a.indexOf(t)>=0||(r[t]=e[t]);return r}(e,a);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)t=l[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var o=n.createContext({}),u=function(e){var a=n.useContext(o),t=a;return e&&(t="function"==typeof e?e(a):s(s({},a),e)),t},p=function(e){var a=u(e.components);return n.createElement(o.Provider,{value:a},e.children)},d="mdxType",c={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},m=n.forwardRef((function(e,a){var t=e.components,r=e.mdxType,l=e.originalType,o=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),d=u(t),m=r,h=d["".concat(o,".").concat(m)]||d[m]||c[m]||l;return t?n.createElement(h,s(s({ref:a},p),{},{components:t})):n.createElement(h,s({ref:a},p))}));function h(e,a){var t=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var l=t.length,s=new Array(l);s[0]=m;var i={};for(var o in a)hasOwnProperty.call(a,o)&&(i[o]=a[o]);i.originalType=e,i[d]="string"==typeof e?e:r,s[1]=i;for(var u=2;u<l;u++)s[u]=t[u];return n.createElement.apply(null,s)}return n.createElement.apply(null,t)}m.displayName="MDXCreateElement"},5162:(e,a,t)=>{t.d(a,{Z:()=>s});var n=t(7294),r=t(6010);const l={tabItem:"tabItem_Ymn6"};function s(e){let{children:a,hidden:t,className:s}=e;return n.createElement("div",{role:"tabpanel",className:(0,r.Z)(l.tabItem,s),hidden:t},a)}},4866:(e,a,t)=>{t.d(a,{Z:()=>N});var n=t(7462),r=t(7294),l=t(6010),s=t(2466),i=t(6550),o=t(1980),u=t(7392),p=t(12);function d(e){return function(e){return r.Children.map(e,(e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:a}=e;return!!a&&"object"==typeof a&&"value"in a}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:a,label:t,attributes:n,default:r}}=e;return{value:a,label:t,attributes:n,default:r}}))}function c(e){const{values:a,children:t}=e;return(0,r.useMemo)((()=>{const e=a??d(t);return function(e){const a=(0,u.l)(e,((e,a)=>e.value===a.value));if(a.length>0)throw new Error(`Docusaurus error: Duplicate values "${a.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[a,t])}function m(e){let{value:a,tabValues:t}=e;return t.some((e=>e.value===a))}function h(e){let{queryString:a=!1,groupId:t}=e;const n=(0,i.k6)(),l=function(e){let{queryString:a=!1,groupId:t}=e;if("string"==typeof a)return a;if(!1===a)return null;if(!0===a&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:a,groupId:t});return[(0,o._X)(l),(0,r.useCallback)((e=>{if(!l)return;const a=new URLSearchParams(n.location.search);a.set(l,e),n.replace({...n.location,search:a.toString()})}),[l,n])]}function g(e){const{defaultValue:a,queryString:t=!1,groupId:n}=e,l=c(e),[s,i]=(0,r.useState)((()=>function(e){let{defaultValue:a,tabValues:t}=e;if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(a){if(!m({value:a,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${a}" but none of its children has the corresponding value. Available values are: ${t.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return a}const n=t.find((e=>e.default))??t[0];if(!n)throw new Error("Unexpected error: 0 tabValues");return n.value}({defaultValue:a,tabValues:l}))),[o,u]=h({queryString:t,groupId:n}),[d,g]=function(e){let{groupId:a}=e;const t=function(e){return e?`docusaurus.tab.${e}`:null}(a),[n,l]=(0,p.Nk)(t);return[n,(0,r.useCallback)((e=>{t&&l.set(e)}),[t,l])]}({groupId:n}),b=(()=>{const e=o??d;return m({value:e,tabValues:l})?e:null})();(0,r.useLayoutEffect)((()=>{b&&i(b)}),[b]);return{selectedValue:s,selectValue:(0,r.useCallback)((e=>{if(!m({value:e,tabValues:l}))throw new Error(`Can't select invalid tab value=${e}`);i(e),u(e),g(e)}),[u,g,l]),tabValues:l}}var b=t(2389);const k={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};function y(e){let{className:a,block:t,selectedValue:i,selectValue:o,tabValues:u}=e;const p=[],{blockElementScrollPositionUntilNextRender:d}=(0,s.o5)(),c=e=>{const a=e.currentTarget,t=p.indexOf(a),n=u[t].value;n!==i&&(d(a),o(n))},m=e=>{let a=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=p.indexOf(e.currentTarget)+1;a=p[t]??p[0];break}case"ArrowLeft":{const t=p.indexOf(e.currentTarget)-1;a=p[t]??p[p.length-1];break}}a?.focus()};return r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,l.Z)("tabs",{"tabs--block":t},a)},u.map((e=>{let{value:a,label:t,attributes:s}=e;return r.createElement("li",(0,n.Z)({role:"tab",tabIndex:i===a?0:-1,"aria-selected":i===a,key:a,ref:e=>p.push(e),onKeyDown:m,onClick:c},s,{className:(0,l.Z)("tabs__item",k.tabItem,s?.className,{"tabs__item--active":i===a})}),t??a)})))}function f(e){let{lazy:a,children:t,selectedValue:n}=e;const l=(Array.isArray(t)?t:[t]).filter(Boolean);if(a){const e=l.find((e=>e.props.value===n));return e?(0,r.cloneElement)(e,{className:"margin-top--md"}):null}return r.createElement("div",{className:"margin-top--md"},l.map(((e,a)=>(0,r.cloneElement)(e,{key:a,hidden:e.props.value!==n}))))}function v(e){const a=g(e);return r.createElement("div",{className:(0,l.Z)("tabs-container",k.tabList)},r.createElement(y,(0,n.Z)({},e,a)),r.createElement(f,(0,n.Z)({},e,a)))}function N(e){const a=(0,b.Z)();return r.createElement(v,(0,n.Z)({key:String(a)},e))}},940:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>p,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>u,toc:()=>d});var n=t(7462),r=(t(7294),t(3905)),l=t(4866),s=t(5162);const i={sidebar_position:3,description:"The Pathling library can be used to query datasets of FHIR resources using FHIRPath. This is useful for aggregating data, and creating custom views."},o="FHIRPath query",u={unversionedId:"libraries/fhirpath-query",id:"libraries/fhirpath-query",title:"FHIRPath query",description:"The Pathling library can be used to query datasets of FHIR resources using FHIRPath. This is useful for aggregating data, and creating custom views.",source:"@site/docs/libraries/fhirpath-query.md",sourceDirName:"libraries",slug:"/libraries/fhirpath-query",permalink:"/docs/libraries/fhirpath-query",draft:!1,editUrl:"https://github.com/aehrc/pathling/tree/main/site/docs/libraries/fhirpath-query.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3,description:"The Pathling library can be used to query datasets of FHIR resources using FHIRPath. This is useful for aggregating data, and creating custom views."},sidebar:"libraries",previous:{title:"Parquet specification",permalink:"/docs/libraries/encoders/schema"},next:{title:"Terminology functions",permalink:"/docs/libraries/terminology"}},p={},d=[{value:"Extract",id:"extract",level:2},{value:"Aggregate",id:"aggregate",level:2},{value:"Reading FHIR data",id:"reading-fhir-data",level:2},{value:"NDJSON",id:"ndjson",level:3},{value:"FHIR Bundles",id:"fhir-bundles",level:3},{value:"Datasets",id:"datasets",level:3},{value:"Parquet",id:"parquet",level:3},{value:"Delta Lake",id:"delta-lake",level:3},{value:"Managed tables",id:"managed-tables",level:3},{value:"Writing FHIR data",id:"writing-fhir-data",level:2},{value:"NDJSON",id:"ndjson-1",level:3},{value:"Parquet",id:"parquet-1",level:3},{value:"Delta Lake",id:"delta-lake-1",level:3},{value:"Managed tables",id:"managed-tables-1",level:3}],c={toc:d},m="wrapper";function h(e){let{components:a,...t}=e;return(0,r.kt)(m,(0,n.Z)({},c,t,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"fhirpath-query"},"FHIRPath query"),(0,r.kt)("p",null,"The Pathling library can be used to query datasets of FHIR resources\nusing ",(0,r.kt)("a",{parentName:"p",href:"../fhirpath"},"FHIRPath"),". This is useful for aggregating data, and creating\ncustom views."),(0,r.kt)("h2",{id:"extract"},"Extract"),(0,r.kt)("p",null,"This operation allows a user to create arbitrary tabular extracts from FHIR\ndata, by specifying columns in terms of set of FHIRPath expressions that are\nused to populate them. This is useful for preparing data for use within other\ntools, and helps to alleviate some of the burden of dealing with FHIR data in\nits raw form."),(0,r.kt)("p",null,"The query can also be optionally filtered by a set of FHIRPath expressions,\nwhich are combined using Boolean AND logic."),(0,r.kt)(l.Z,{mdxType:"Tabs"},(0,r.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from pathling import PathlingContext, Expression as exp\n\npc = PathlingContext.create()\ndata = pc.read.ndjson("s3://somebucket/synthea/ndjson")\n\n# For patients that have not received a COVID-19 vaccine, extract the given \n# name, family name, phone number and whether the patient has heart disease.\nresult = data.extract("Patient",\n                      columns=[\n                          exp("name.first().given.first()", "Given name"),\n                          exp("name.first().family", "Family name"),\n                          exp("telecom.where(system = \'phone\').value",\n                              "Phone number"),\n                          exp("reverseResolve(Condition.subject).exists("\n                              "code.subsumedBy(http://snomed.info/sct|56265001))",\n                              "Heart disease")\n                      ],\n                      filters=[\n                          "reverseResolve(Immunization.patient).vaccineCode"\n                          ".exists(memberOf(\'https://aehrc.csiro.au/fhir/ValueSet/covid-19-vaccines\'))"\n                          ".not()"]\n                      )\ndisplay(result)\n'))),(0,r.kt)(s.Z,{value:"r",label:"R",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-r"},'library(sparklyr)\nlibrary(pathling)\n\npc <- pathling_connect()\ndata <- pc %>% pathling_read_ndjson("s3://somebucket/synthea/ndjson")\n\n# For patients that have not received a COVID-19 vaccine, extract the given\n# name, family name, phone number and whether the patient has heart disease.\nresult <- data %>%\n        ds_extract(\n                "Patient",\n                columns = c(\n                        "Given name" = "name.first().given.first()",\n                        "Family name" = "name.first().family",\n                        "Phone number" = "telecom.where(system = \'phone\').value",\n                        "Heart disease" = "reverseResolve(Condition.subject).exists(code.subsumedBy(http://snomed.info/sct|56265001))"\n                ),\n                filters = c("Heart disease" = "reverseResolve(Condition.subject).exists(code.subsumedBy(http://snomed.info/sct|56265001))")\n        ) %>%\n        show()\n\npc %>% pathling_disconnect()\n'))),(0,r.kt)(s.Z,{value:"scala",label:"Scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import au.csiro.pathling.library.PathlingContext\nimport org.apache.spark.sql.SparkSession\nimport org.hl7.fhir.r4.model.Enumerations.ResourceType\n\nval pc = PathlingContext.create(spark, terminologyConfig)\nval data = pc.read.ndjson("s3://somebucket/synthea/ndjson")\n\n// For patients that have not received a COVID-19 vaccine, extract the given\n// name, family name, phone number and whether the patient has heart disease.\nval result = data.extract(ResourceType.PATIENT)\n        .column("name.first().given.first()", "Given name")\n        .column("name.first().family", "Family name")\n        .column("telecom.where(system = \'phone\').value", "Phone number")\n        .column("reverseResolve(Condition.subject)" +\n                ".exists(code.subsumedBy(http://snomed.info/sct|56265001))", "Heart disease")\n        .filter("reverseResolve(Immunization.patient).vaccineCode" +\n                ".memberOf(\'https://aehrc.csiro.au/fhir/ValueSet/covid-19-vaccines\').allFalse()")\n        .execute()\n\ndisplay(result)\n'))),(0,r.kt)(s.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'import au.csiro.pathling.library.PathlingContext;\nimport org.apache.spark.sql.SparkSession;\nimport org.apache.spark.sql.Dataset;\nimport org.apache.spark.sql.Row;\nimport org.hl7.fhir.r4.model.Enumerations.ResourceType;\nimport au.csiro.pathling.library.io.source.NdjsonSource;\n\nclass MyApp {\n\n    public static void main(String[] args) {\n        PathlingContext pc = PathlingContext.create();\n        NdjsonSource data = pc.read.ndjson("s3://somebucket/synthea/ndjson");\n\n        // For patients that have not received a COVID-19 vaccine, extract the given\n        // name, family name, phone number and whether the patient has heart disease.\n        Dataset<Row> result = data.extract(ResourceType.PATIENT)\n                .column("name.first().given.first()", "Given name")\n                .column("name.first().family", "Family name")\n                .column("telecom.where(system = \'phone\').value", "Phone number")\n                .column("reverseResolve(Condition.subject)"\n                                + ".exists(code.subsumedBy(http://snomed.info/sct|56265001))",\n                        "Heart disease")\n                .filter("reverseResolve(Immunization.patient).vaccineCode"\n                        + ".memberOf(\'https://aehrc.csiro.au/fhir/ValueSet/covid-19-vaccines\').allFalse()")\n                .execute();\n\n        result.show();\n    }\n}\n\n')))),(0,r.kt)("p",null,"The result of this query would look something like this:"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Given name"),(0,r.kt)("th",{parentName:"tr",align:null},"Family name"),(0,r.kt)("th",{parentName:"tr",align:null},"Phone number"),(0,r.kt)("th",{parentName:"tr",align:null},"Heart disease"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"John"),(0,r.kt)("td",{parentName:"tr",align:null},"Smith"),(0,r.kt)("td",{parentName:"tr",align:null},"0412345678"),(0,r.kt)("td",{parentName:"tr",align:null},"false")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Jane"),(0,r.kt)("td",{parentName:"tr",align:null},"Doe"),(0,r.kt)("td",{parentName:"tr",align:null},"0412345678"),(0,r.kt)("td",{parentName:"tr",align:null},"true")))),(0,r.kt)("h2",{id:"aggregate"},"Aggregate"),(0,r.kt)("p",null,"This operation allows a user to perform aggregate queries on FHIR data, by\nspecifying aggregation, grouping and filter expressions. Grouped results are\nreturned."),(0,r.kt)("p",null,"The aggregate operation is useful for exploratory data analysis, as well as\npowering visualisations and other summarized views of the data."),(0,r.kt)(l.Z,{mdxType:"Tabs"},(0,r.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from pathling import PathlingContext, Expression as exp\n\npc = PathlingContext.create()\ndata = pc.read.ndjson("s3://somebucket/synthea/ndjson")\n\n# Count the number of female patients, grouped by the type of diabetes that they \n# have been diagnosed with.\nresult = data.aggregate(\n        "Patient",\n        aggregations=[exp("count()", "Number of patients")],\n        groupings=[\n            exp("reverseResolve(Condition.subject)"\n                ".where(code.subsumedBy(http://snomed.info/sct|73211009))" +\n                ".code.coding.display()",\n                "Type of diabetes")\n        ],\n        filters=["gender = \'female\'"],\n)\n\ndisplay(result)\n'))),(0,r.kt)(s.Z,{value:"r",label:"R",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-r"},'library(sparklyr)\nlibrary(pathling)\n\npc <- pathling_connect()\ndata <- pc %>% pathling_read_ndjson("s3://somebucket/synthea/ndjson")\n\n# Count the number of female patients, grouped by the type of diabetes that they\n# have been diagnosed with.\nresult <- data %>%\n        ds_aggregate(\n                "Patient",\n                aggregations = c("Number of patients" = "count()"),\n                groupings = c(\n                        "Type of diabetes" = "reverseResolve(Condition.subject).where(code.subsumedBy(http://snomed.info/sct|73211009)).code.coding.display()"),\n                filters = "gender = \'female\'"\n        ) %>% show()\n\npc %>% pathling_disconnect()\n'))),(0,r.kt)(s.Z,{value:"scala",label:"Scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import au.csiro.pathling.library.PathlingContext\nimport org.apache.spark.sql.SparkSession\nimport org.hl7.fhir.r4.model.Enumerations.ResourceType\n\nval pc = PathlingContext.create()\nval data = pc.read.ndjson("s3://somebucket/synthea/ndjson")\n\n// Count the number of female patients, grouped by the type of diabetes that they\n// have been diagnosed with.\nval result = data.aggregate(ResourceType.PATIENT)\n        .aggregation("count()", "Number of patients")\n        .grouping("reverseResolve(Condition.subject)" +\n                  ".where(code.subsumedBy(http://snomed.info/sct|73211009))" +\n                  ".code.coding.display()",\n            "Type of diabetes")\n        .filter("gender = \'female\'")\n        .execute()\n\ndisplay(result)\n'))),(0,r.kt)(s.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'import au.csiro.pathling.library.PathlingContext;\nimport org.apache.spark.sql.SparkSession;\nimport org.apache.spark.sql.Dataset;\nimport org.apache.spark.sql.Row;\nimport org.hl7.fhir.r4.model.Enumerations.ResourceType;\nimport au.csiro.pathling.library.io.source.NdjsonSource;\n\nclass MyApp {\n\n    public static void main(String[] args) {\n        PathlingContext pc = PathlingContext.create();\n        NdjsonSource data = pc.read.ndjson("s3://somebucket/synthea/ndjson");\n\n        // Count the number of female patients, grouped by the type of diabetes that they\n        // have been diagnosed with.\n        Dataset<Row> result = data.aggregate(ResourceType.PATIENT)\n                .aggregation("count()", "Number of patients")\n                .grouping("reverseResolve(Condition.subject)" +\n                          ".where(code.subsumedBy(http://snomed.info/sct|73211009))" + \n                          ".code.coding.display()",\n                        "Type of diabetes")\n                .filter("gender = \'female\'")\n                .execute();\n\n        result.show();\n    }\n}\n')))),(0,r.kt)("p",null,"The result of this query would look something like this:"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Type of diabetes"),(0,r.kt)("th",{parentName:"tr",align:null},"Number of patients"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Diabetes mellitus due to cystic fibrosis"),(0,r.kt)("td",{parentName:"tr",align:null},"3")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Type 2 diabetes mellitus"),(0,r.kt)("td",{parentName:"tr",align:null},"122")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Type 1 diabetes mellitus"),(0,r.kt)("td",{parentName:"tr",align:null},"14")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"NULL"),(0,r.kt)("td",{parentName:"tr",align:null},"1472")))),(0,r.kt)("h2",{id:"reading-fhir-data"},"Reading FHIR data"),(0,r.kt)("p",null,"There are several ways of making FHIR data available for FHIRPath query."),(0,r.kt)("h3",{id:"ndjson"},"NDJSON"),(0,r.kt)("p",null,"You can load all the ",(0,r.kt)("a",{parentName:"p",href:"https://hl7.org/fhir/R4/nd-json.html"},"NDJSON")," files from a\ndirectory, assuming the following naming scheme:"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"[resource type].ndjson")," OR ",(0,r.kt)("inlineCode",{parentName:"p"},"[resource type].[tag].ndjson")),(0,r.kt)("p",null,"Pathling will detect the resource type from the file name, and convert it to a\nSpark dataset using the corresponding resource encoder."),(0,r.kt)("p",null,"The tag can be any string, and is used to accommodate multiple different files\nthat contain the same resource type. For example, you might have one file called\n",(0,r.kt)("inlineCode",{parentName:"p"},"Observation.chart.ndjson")," and another called ",(0,r.kt)("inlineCode",{parentName:"p"},"Observation.lab.ndjson"),"."),(0,r.kt)(l.Z,{mdxType:"Tabs"},(0,r.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'data = pc.read.ndjson("/usr/share/staging/ndjson")\n'))),(0,r.kt)(s.Z,{value:"r",label:"R",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-r"},'data <- pc %>% pathling_read_ndjson("/usr/share/staging/ndjson")\n'))),(0,r.kt)(s.Z,{value:"scala",label:"Scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val data = pc.read().ndjson("/usr/share/staging/ndjson")\n'))),(0,r.kt)(s.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'NdjsonSource data = pc.read().ndjson("/usr/share/staging/ndjson");\n')))),(0,r.kt)("p",null,"You can also accommodate a custom naming scheme within the NDJSON files by using\nthe ",(0,r.kt)("a",{parentName:"p",href:"https://pathling.csiro.au/docs/python/pathling.html#pathling.datasource.DataSources.ndjson"},"file_name_mapper"),"\nargument. Here is an example of how to import the\n",(0,r.kt)("a",{parentName:"p",href:"https://physionet.org/content/mimic-iv-fhir/1.0/"},"MIMIC-IV FHIR data set"),":"),(0,r.kt)(l.Z,{mdxType:"Tabs"},(0,r.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'data = pc.read.ndjson(\n        "/usr/share/staging/ndjson",\n        file_name_mapper=lambda file_name: re.findall(r"Mimic(\\w+?)(?:ED|ICU|"\n        r"Chartevents|Datetimeevents|Labevents|MicroOrg|MicroSusc|MicroTest|"\n        r"Outputevents|Lab|Mix|VitalSigns|VitalSignsED)?$", file_name))\n')))),(0,r.kt)("h3",{id:"fhir-bundles"},"FHIR Bundles"),(0,r.kt)("p",null,"You can load data from a directory containing either JSON or\nXML ",(0,r.kt)("a",{parentName:"p",href:"https://hl7.org/fhir/R4/bundle.html"},"FHIR Bundles"),". The specified resource\ntypes will be extracted from the Bundles and made available for query."),(0,r.kt)(l.Z,{mdxType:"Tabs"},(0,r.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'data = pc.read.bundles("/usr/share/staging/bundles",\n                       resource_types=["Patient", "Condition", "Immunization"])\n'))),(0,r.kt)(s.Z,{value:"r",label:"R",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-r"},'data <- pc %>% pathling_read_bundles("/usr/share/staging/bundles",\n                                resource_types = c("Patient", "Condition", "Immunization"))\n'))),(0,r.kt)(s.Z,{value:"scala",label:"Scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val data = pc.read().bundles("/usr/share/staging/bundles",\n    Set("Patient", "Condition", "Immunization").asJava, FhirMimeTypes.FHIR_JSON)\n'))),(0,r.kt)(s.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'BundlesSource data = pc.read().bundles("/usr/share/staging/bundles",\n        Set.of("Patient","Condition","Immunization"),FhirMimeTypes.FHIR_JSON) \n')))),(0,r.kt)("h3",{id:"datasets"},"Datasets"),(0,r.kt)("p",null,"You can make data that is already held in Spark datasets available for query\nusing the ",(0,r.kt)("inlineCode",{parentName:"p"},"datasets")," method. This method returns an object that can be populated\nwith pairs of resource type and dataset, using the ",(0,r.kt)("inlineCode",{parentName:"p"},"dataset")," method."),(0,r.kt)(l.Z,{mdxType:"Tabs"},(0,r.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'data = pc.read.datasets({\n    "Patient": patient_dataset,\n    "Condition": condition_dataset,\n    "Immunization": immunization_dataset,\n})\n'))),(0,r.kt)(s.Z,{value:"r",label:"R",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-r"},"data <- pc %>% pathling_read_datasets(list(\n        Patient = patient_dataset,\n        Condition = condition_dataset,\n        Immunization = immunization_dataset\n))\n"))),(0,r.kt)(s.Z,{value:"scala",label:"Scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val data = pc.read().datasets()\n        .dataset("Patient", patientDataset)\n        .dataset("Condition", conditionDataset)\n        .dataset("Immunization", immunizationDataset)\n'))),(0,r.kt)(s.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'DatasetSource data = pc.read().datasets()\n        .dataset("Patient",patientDataset)\n        .dataset("Condition",conditionDataset)\n        .dataset("Immunization",immunizationDataset);\n')))),(0,r.kt)("h3",{id:"parquet"},"Parquet"),(0,r.kt)("p",null,"You can load data from a directory\ncontaining ",(0,r.kt)("a",{parentName:"p",href:"https://parquet.apache.org/"},"Parquet")," files. The Parquet files must\nhave been saved using the schema used by the Pathling encoders (\nsee ",(0,r.kt)("a",{parentName:"p",href:"#parquet-1"},"Writing FHIR data"),")."),(0,r.kt)("p",null,"The files are assumed to be named according to their resource\ntype (",(0,r.kt)("inlineCode",{parentName:"p"},"[resource type].parquet"),"), e.g. ",(0,r.kt)("inlineCode",{parentName:"p"},"Patient.parquet"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"Condition.parquet"),"."),(0,r.kt)(l.Z,{mdxType:"Tabs"},(0,r.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'data = pc.read.parquet("/usr/share/staging/parquet")\n'))),(0,r.kt)(s.Z,{value:"r",label:"R",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-r"},'data <- pc %>% pathling_read_parquet("/usr/share/staging/parquet")\n'))),(0,r.kt)(s.Z,{value:"scala",label:"Scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val data = pc.read().parquet("/usr/share/staging/parquet")\n'))),(0,r.kt)(s.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'ParquetSource data = pc.read().parquet("/usr/share/staging/parquet");\n')))),(0,r.kt)("h3",{id:"delta-lake"},"Delta Lake"),(0,r.kt)("p",null,"You can load data from a directory containing ",(0,r.kt)("a",{parentName:"p",href:"https://delta.io/"},"Delta Lake"),"\ntables. Delta tables are a specialisation of Parquet that enable additional\nfunctionality, such as incremental update and history. The Delta tables must\nhave been saved using the schema used by the Pathling encoders\n(see ",(0,r.kt)("a",{parentName:"p",href:"#delta-lake-1"},"Writing FHIR data"),")."),(0,r.kt)("p",null,"Note that you will need to use\nthe ",(0,r.kt)("a",{parentName:"p",href:"https://pathling.csiro.au/docs/python/pathling.html#pathling.context.PathlingContext"},"enable_delta"),"\nparameter when initialising the Pathling context."),(0,r.kt)("p",null,"The files are assumed to be named according to their resource\ntype (",(0,r.kt)("inlineCode",{parentName:"p"},"[resource type].parquet"),"), e.g. ",(0,r.kt)("inlineCode",{parentName:"p"},"Patient.parquet"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"Condition.parquet"),"."),(0,r.kt)(l.Z,{mdxType:"Tabs"},(0,r.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'data = pc.read.delta("/usr/share/staging/delta")\n'))),(0,r.kt)(s.Z,{value:"r",label:"R",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-r"},'data <- pc %>% pathling_read_delta("/usr/share/staging/delta")\n'))),(0,r.kt)(s.Z,{value:"scala",label:"Scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val data = pc.read().delta("/usr/share/staging/delta")\n'))),(0,r.kt)(s.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'DeltaSource data = pc.read().delta("/usr/share/staging/delta");\n')))),(0,r.kt)("h3",{id:"managed-tables"},"Managed tables"),(0,r.kt)("p",null,"You can load data from managed tables that have previously been saved within\nthe ",(0,r.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/sql-data-sources-hive-tables.html"},"Spark catalog"),".\nYou can optionally specify a schema that will be used to locate the tables,\notherwise the default schema will be used."),(0,r.kt)("p",null,"The tables are assumed to be named according to their resource\ntype, e.g. ",(0,r.kt)("inlineCode",{parentName:"p"},"Patient"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"Condition"),"."),(0,r.kt)("p",null,"This also works with\nthe ",(0,r.kt)("a",{parentName:"p",href:"https://docs.databricks.com/data-governance/unity-catalog/index.html"},"Unity Catalog"),"\nfeature of Databricks."),(0,r.kt)(l.Z,{mdxType:"Tabs"},(0,r.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'data = pc.read.tables("mimic-iv")\n'))),(0,r.kt)(s.Z,{value:"r",label:"R",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-r"},'data <- pc %>% pathling_read_tables("mimic-iv")\n'))),(0,r.kt)(s.Z,{value:"scala",label:"Scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val data = pc.read().tables("mimic-iv")\n'))),(0,r.kt)(s.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'CatalogSource data = pc.read().tables("mimic-iv");\n')))),(0,r.kt)("h2",{id:"writing-fhir-data"},"Writing FHIR data"),(0,r.kt)("p",null,"Once you have read data in from a data source, you can also optionally write it\nback out to a variety of targets. This is useful for persisting source data in a\nmore efficient form for query (e.g. Parquet or Delta), or for exporting data to\nNDJSON for use in other systems."),(0,r.kt)("h3",{id:"ndjson-1"},"NDJSON"),(0,r.kt)("p",null,"You can write data to a directory containing NDJSON files. The files are named\naccording to their resource type (",(0,r.kt)("inlineCode",{parentName:"p"},"[resource type].ndjson"),"), e.g.\n",(0,r.kt)("inlineCode",{parentName:"p"},"Patient.ndjson"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"Condition.ndjson"),"."),(0,r.kt)(l.Z,{mdxType:"Tabs"},(0,r.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'data.write.ndjson("/tmp/ndjson")\n'))),(0,r.kt)(s.Z,{value:"r",label:"R",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-r"},'data %>% ds_write_ndjson("/tmp/ndjson")\n'))),(0,r.kt)(s.Z,{value:"scala",label:"Scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'data.write().ndjson("/tmp/ndjson")\n'))),(0,r.kt)(s.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'data.write().ndjson("/tmp/ndjson");\n')))),(0,r.kt)("h3",{id:"parquet-1"},"Parquet"),(0,r.kt)("p",null,"You can write data to a directory\ncontaining ",(0,r.kt)("a",{parentName:"p",href:"https://parquet.apache.org/"},"Parquet")," files. The files are named\naccording to their resource type (",(0,r.kt)("inlineCode",{parentName:"p"},"[resource type].parquet"),"),\ne.g. ",(0,r.kt)("inlineCode",{parentName:"p"},"Patient.parquet"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"Condition.parquet"),"."),(0,r.kt)(l.Z,{mdxType:"Tabs"},(0,r.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'data.write.parquet("/usr/share/warehouse/parquet")\n'))),(0,r.kt)(s.Z,{value:"r",label:"R",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-r"},'data %>% ds_write_parquet("/usr/share/warehouse/parquet")\n'))),(0,r.kt)(s.Z,{value:"scala",label:"Scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'data.write().parquet("/usr/share/warehouse/parquet")\n'))),(0,r.kt)(s.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'data.write().parquet("/usr/share/warehouse/parquet");\n')))),(0,r.kt)("h3",{id:"delta-lake-1"},"Delta Lake"),(0,r.kt)("p",null,"You can write data to a directory containing ",(0,r.kt)("a",{parentName:"p",href:"https://delta.io/"},"Delta Lake"),"\ntables. Delta tables are a specialisation of Parquet that enable additional\nfunctionality, such as incremental update and history."),(0,r.kt)("p",null,"Note that you will need to use\nthe ",(0,r.kt)("a",{parentName:"p",href:"https://pathling.csiro.au/docs/python/pathling.html#pathling.context.PathlingContext"},"enable_delta"),"\nparameter when initialising the Pathling context."),(0,r.kt)("p",null,"The files are named according to their resource\ntype (",(0,r.kt)("inlineCode",{parentName:"p"},"[resource type].parquet"),"), e.g. ",(0,r.kt)("inlineCode",{parentName:"p"},"Patient.parquet"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"Condition.parquet"),"."),(0,r.kt)(l.Z,{mdxType:"Tabs"},(0,r.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'data.write.delta("/usr/share/warehouse/delta")\n'))),(0,r.kt)(s.Z,{value:"r",label:"R",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-r"},'data %>% ds_write_delta("/usr/share/warehouse/delta")\n'))),(0,r.kt)(s.Z,{value:"scala",label:"Scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'data.write().delta("/usr/share/warehouse/delta")\n'))),(0,r.kt)(s.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'data.write().delta("/usr/share/warehouse/delta");\n')))),(0,r.kt)("h3",{id:"managed-tables-1"},"Managed tables"),(0,r.kt)("p",null,"You can write data to managed tables that will be saved within\nthe ",(0,r.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/sql-data-sources-hive-tables.html"},"Spark catalog"),".\nYou can optionally specify a schema that will be used to locate the tables,\notherwise the default schema will be used."),(0,r.kt)("p",null,"The tables are named according to their resource type,\ne.g. ",(0,r.kt)("inlineCode",{parentName:"p"},"Patient"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"Condition"),"."),(0,r.kt)("p",null,"This also works with\nthe ",(0,r.kt)("a",{parentName:"p",href:"https://docs.databricks.com/data-governance/unity-catalog/index.html"},"Unity Catalog"),"\nfeature of Databricks."),(0,r.kt)(l.Z,{mdxType:"Tabs"},(0,r.kt)(s.Z,{value:"python",label:"Python",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'data.write.tables("test")\n'))),(0,r.kt)(s.Z,{value:"r",label:"R",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-r"},'data %>% ds_write_tables("test")\n'))),(0,r.kt)(s.Z,{value:"scala",label:"Scala",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'data.write().tables("test")\n'))),(0,r.kt)(s.Z,{value:"java",label:"Java",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'data.write().tables("test");\n')))))}h.isMDXComponent=!0}}]);